{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torcheval.metrics import Mean, MulticlassAccuracy\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "\n",
    "from aum_ranking import assign_threshold_samples, ThresholdSamplesDataset, AUM, compute_aum_threshold, flag_mislabeled_examples, combine_mislabeled_examples\n",
    "from models import ResNet32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download datasets\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root=\"data\", train=True, download=True, transform=torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Pad(4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomCrop(32)\n",
    "]))\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=\"data\", train=False, download=True, transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign two sets of threshold samples\n",
    "\n",
    "threshold_sample_flags_1, threshold_sample_flags_2 = assign_threshold_samples(num_examples=len(train_dataset), num_classes=len(train_dataset.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of classes: {len(train_dataset.classes)}\")\n",
    "print(f\"Number of samples: {len(train_dataset)}\")\n",
    "print(f\"Number of threshold samples (first pass): {threshold_sample_flags_1.sum()}\")\n",
    "print(f\"Number of threshold samples (second pass): {threshold_sample_flags_2.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for visualizing predictions\n",
    "\n",
    "to_pil_image = torchvision.transforms.ToPILImage()\n",
    "\n",
    "\n",
    "def predict_with_probs(model, x):\n",
    "    \"\"\"\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    \"\"\"\n",
    "    logits = model(x)\n",
    "    output = F.softmax(logits, dim=1)\n",
    "    probs, preds = torch.max(output, 1)\n",
    "    return preds, probs\n",
    "\n",
    "\n",
    "def plot_classes_preds(model, x, y, classes):\n",
    "    \"\"\"\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        preds, probs = predict_with_probs(model, x.to(device))\n",
    "    preds = preds.cpu().numpy()\n",
    "    probs = probs.cpu().numpy()\n",
    "    # Plot the images in the batch, along with predicted and true labels\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(10, 3))\n",
    "    for i, ax in enumerate(axs):\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "        ax.imshow(to_pil_image(x[i]))\n",
    "        ax.set_title(\n",
    "            \"{0}, {1:.1%}\\n(actual: {2})\".format(\n",
    "                classes[preds[i]],\n",
    "                probs[i],\n",
    "                classes[y[i]]),\n",
    "            color=(\"green\" if preds[i]==y[i].item() else \"red\")\n",
    "        )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader, model, loss_fn, optimizer, epoch, writer, loss_metric, accuracy_metric, aum):\n",
    "    model.train()\n",
    "    with tqdm(loader) as progress:\n",
    "        for batch, (x, y, indexes) in enumerate(progress):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss_metric.update(loss.detach())\n",
    "            accuracy_metric.update(pred, y)\n",
    "\n",
    "            progress.set_postfix_str(\n",
    "                f\"loss={loss_metric.compute().item():.4f}, accuracy={accuracy_metric.compute().item():.2%}\",\n",
    "                refresh=False\n",
    "            )\n",
    "\n",
    "            aum.update(pred, y, indexes)\n",
    "\n",
    "    writer.add_scalar(\"loss/train\", scalar_value=loss_metric.compute(), global_step=epoch)\n",
    "    loss_metric.reset()\n",
    "    writer.add_scalar(\"accuracy/train\", scalar_value=accuracy_metric.compute(), global_step=epoch)\n",
    "    accuracy_metric.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, model, loss_fn, epoch, writer, loss_metric, accuracy_metric, classes):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            loss_metric.update(loss)\n",
    "            accuracy_metric.update(pred, y)\n",
    "    \n",
    "    print(f\"test_loss={loss_metric.compute().item():.4f}, test_accuracy={accuracy_metric.compute().item():.2%}\")\n",
    "\n",
    "    writer.add_scalar(\"loss/test\", scalar_value=loss_metric.compute(), global_step=epoch)\n",
    "    loss_metric.reset()\n",
    "    writer.add_scalar(\"accuracy/test\", scalar_value=accuracy_metric.compute(), global_step=epoch)\n",
    "    accuracy_metric.reset()\n",
    "\n",
    "    x, y = zip(*random.choices(loader.dataset, k=4))\n",
    "    x = torch.stack(x)\n",
    "    y = torch.tensor(y)\n",
    "    writer.add_figure(\"predictions\", plot_classes_preds(model, x, y, classes), global_step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_run(pass_index, threshold_dataset, test_dataset, epochs, aum):\n",
    "    # Make data loaders\n",
    "    batch_size = 64\n",
    "    threshold_loader = DataLoader(threshold_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # Build model\n",
    "    model = ResNet32(num_classes=len(threshold_dataset.classes)).to(device)\n",
    "\n",
    "    # Set loss function and optimizer\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4, momentum=0.9, nesterov=True)\n",
    "\n",
    "    # Make TensorBoard writer\n",
    "    now = datetime.now().strftime(\"%b%d_%H-%M-%S\")\n",
    "    log_dir = os.path.join(\"runs\", \"find_mislabeled_data\", f\"{now}_pass_{pass_index}\")\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    # Define metrics\n",
    "    loss_metric = Mean(device=device)\n",
    "    accuracy_metric = MulticlassAccuracy(device=device)\n",
    "\n",
    "    # Train the model\n",
    "    print(\"Training model\")\n",
    "    for epoch in range(epochs):\n",
    "        print(\"-------------------------------\")\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        train(threshold_loader, model, loss_fn, optimizer, epoch, writer, loss_metric, accuracy_metric, aum)\n",
    "        test(test_loader, model, loss_fn, epoch, writer, loss_metric, accuracy_metric, classes=threshold_loader.dataset.classes)\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Done!\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mislabeled_examples_pass(pass_index, threshold_sample_flags, train_dataset, test_dataset):\n",
    "    print(f\"Performing pass {pass_index}\")\n",
    "\n",
    "    # Make threshold samples dataset\n",
    "    threshold_dataset = ThresholdSamplesDataset(train_dataset, threshold_sample_flags)\n",
    "\n",
    "    # Create AUM calculator\n",
    "    aum = AUM(num_examples=len(threshold_dataset), device=device)\n",
    "\n",
    "    # Train a model to populate the margin values\n",
    "    epochs = 150\n",
    "    model = training_run(pass_index, threshold_dataset, test_dataset, epochs, aum)\n",
    "\n",
    "    # Compute AUM values\n",
    "    aum_values = aum.compute(epochs).cpu().numpy()\n",
    "    print(f\"AUM values: {aum_values.shape}, {aum_values.dtype}\")\n",
    "    print(f\"mean: {np.mean(aum_values):.4f}, min: {np.min(aum_values):.4f}, max: {np.max(aum_values):.4f}, std: {np.std(aum_values):.4f}\")\n",
    "\n",
    "    # Compute AUM threshold\n",
    "    aum_threshold = compute_aum_threshold(aum_values, threshold_sample_flags)\n",
    "    print(f\"AUM threshold: {aum_threshold}\")\n",
    "\n",
    "    # Flag (potentially) mislabeled examples\n",
    "    mislabeled_example_flags = flag_mislabeled_examples(aum_values, threshold_sample_flags, aum_threshold)\n",
    "    print(f\"Potentially mislabeled examples: {np.sum(mislabeled_example_flags)}\")\n",
    "    print(f\"Finished pass {pass_index}\")\n",
    "    print(\"===============================\")\n",
    "    return mislabeled_example_flags\n",
    "\n",
    "\n",
    "def find_mislabeled_examples(train_dataset, test_dataset, threshold_sample_flags_1, threshold_sample_flags_2):\n",
    "    mislabeled_example_flags_1 = find_mislabeled_examples_pass(1, threshold_sample_flags_1, train_dataset, test_dataset)\n",
    "    mislabeled_example_flags_2 = find_mislabeled_examples_pass(2, threshold_sample_flags_2, train_dataset, test_dataset)\n",
    "    mislabeled_example_flags = combine_mislabeled_examples(mislabeled_example_flags_1, mislabeled_example_flags_2)\n",
    "    return mislabeled_example_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mislabeled_example_flags = find_mislabeled_examples(train_dataset, test_dataset, threshold_sample_flags_1, threshold_sample_flags_2)\n",
    "print(f\"Mislabeled example flags: {mislabeled_example_flags.shape}, {mislabeled_example_flags.dtype}\")\n",
    "print(f\"Potentially mislabeled examples: {np.sum(mislabeled_example_flags)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mislabeled_examples(dataset, mislabeled_example_flags):\n",
    "    (mislabeled_example_indexes,) = np.nonzero(mislabeled_example_flags)\n",
    "    indexes = np.random.choice(mislabeled_example_indexes, 6)\n",
    "    fig, axs = plt.subplots(1, 6, figsize=(15, 3.2))\n",
    "    fig.suptitle(\"Potentially mislabeled examples\")\n",
    "    for i, ax in zip(indexes, axs):\n",
    "        x, y = dataset[i]\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "        ax.imshow(to_pil_image(x))\n",
    "        ax.set_title(f\"{i}\\n{dataset.classes[y]}\")\n",
    "\n",
    "\n",
    "plot_mislabeled_examples(train_dataset, mislabeled_example_flags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
