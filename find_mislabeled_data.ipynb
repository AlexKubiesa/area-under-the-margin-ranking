{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torcheval.metrics import Mean, Metric, MulticlassAccuracy\n",
    "import torchvision\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download datasets\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root=\"data\", train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=\"data\", train=False, download=True, transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_threshold_sample_flags(num_examples, num_classes):\n",
    "    threshold_sample_flags = np.zeros((num_examples,), dtype=np.uint8)\n",
    "    num_threshold_samples = num_examples // (num_classes + 1)\n",
    "    threshold_sample_flags[:num_threshold_samples] = 1\n",
    "    np.random.shuffle(threshold_sample_flags)\n",
    "    return threshold_sample_flags\n",
    "\n",
    "\n",
    "class ThresholdSamplesDataset(Dataset):\n",
    "    \"\"\"A Dataset wrapper that adds threshold samples.\"\"\"\n",
    "    def __init__(self, dataset, threshold_sample_flags):\n",
    "        if not hasattr(dataset, \"classes\"):\n",
    "            raise ValueError(\"dataset must have 'classes' attribute.\")\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.threshold_sample_flags = threshold_sample_flags\n",
    "        self.classes = self.dataset.classes + [\"fake_label\"]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.dataset[index]\n",
    "        if self.threshold_sample_flags[index]:\n",
    "            return x, len(self.dataset.classes)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make threshold samples dataset\n",
    "\n",
    "threshold_sample_flags = make_threshold_sample_flags(num_examples=len(train_dataset), num_classes=len(train_dataset.classes))\n",
    "threshold_dataset = ThresholdSamplesDataset(train_dataset, threshold_sample_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of classes: {len(train_dataset.classes)}\")\n",
    "print(f\"Number of samples: {len(threshold_dataset)}\")\n",
    "print(f\"Number of threshold samples: {sum(1 for x, y in threshold_dataset if y == len(train_dataset.classes))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data loaders\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "threshold_loader = torch.utils.data.DataLoader(threshold_dataset, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "x, y = next(iter(test_loader))\n",
    "print(f\"x: {x.shape}, {x.dtype}\")\n",
    "print(f\"y: {y.shape}, {y.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "\n",
    "model = torchvision.models.resnet34(num_classes=len(threshold_dataset.classes)).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set loss function and optimizer\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make TensorBoard writer\n",
    "\n",
    "now = datetime.now().strftime(\"%b%d_%H-%M-%S\")\n",
    "log_dir = os.path.join(\"runs\", \"find_mislabeled_data\", now)\n",
    "writer = SummaryWriter(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "\n",
    "loss_metric = Mean(device=device)\n",
    "accuracy_metric = MulticlassAccuracy(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for visualizing predictions\n",
    "\n",
    "to_pil_image = torchvision.transforms.ToPILImage()\n",
    "\n",
    "\n",
    "def predict_with_probs(model, x):\n",
    "    \"\"\"\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    \"\"\"\n",
    "    logits = model(x)\n",
    "    output = F.softmax(logits, dim=1)\n",
    "    probs, preds = torch.max(output, 1)\n",
    "    return preds, probs\n",
    "\n",
    "\n",
    "def plot_classes_preds(model, x, y, classes):\n",
    "    \"\"\"\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        preds, probs = predict_with_probs(model, x.to(device))\n",
    "    preds = preds.cpu().numpy()\n",
    "    probs = probs.cpu().numpy()\n",
    "    # Plot the images in the batch, along with predicted and true labels\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(10, 3))\n",
    "    for i, ax in enumerate(axs):\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "        ax.imshow(to_pil_image(x[i]))\n",
    "        ax.set_title(\n",
    "            \"{0}, {1:.1%}\\n(actual: {2})\".format(\n",
    "                classes[preds[i]],\n",
    "                probs[i],\n",
    "                classes[y[i]]),\n",
    "            color=(\"green\" if preds[i]==y[i].item() else \"red\")\n",
    "        )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define AUM (area under margin)\n",
    "\n",
    "class AUM:\n",
    "    def __init__(self, num_examples, device=None):\n",
    "        self.num_examples = num_examples\n",
    "        self.device = device\n",
    "        self.reset()\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def update(self, logits, y, start):\n",
    "        \"\"\"\n",
    "        Updates states with the ground truth labels and predictions.\n",
    "\n",
    "        Args:\n",
    "            pred (Tensor): Tensor of label predictions logits of shape (batch_size,\n",
    "                num_classes).\n",
    "            y (Tensor): Tensor of ground truth labels with shape (batch_size,).\n",
    "            start (int): Index of the first example within the dataset.\n",
    "        \"\"\"\n",
    "        logits = logits.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "\n",
    "        # Get the logits for the ground truth labels\n",
    "        batch_size = y.shape[0]\n",
    "        assigned_logits = logits[torch.arange(batch_size), y]\n",
    "\n",
    "        # Get the next highest logits\n",
    "        masked_logits = torch.scatter(logits, dim=1, index=y[..., None], value=-torch.inf)\n",
    "        largest_other_logits, _ = torch.max(masked_logits, dim=1)\n",
    "\n",
    "        # Calculate the margins\n",
    "        margins = assigned_logits - largest_other_logits\n",
    "\n",
    "        # Accumulate the margin totals\n",
    "        stop = start + batch_size\n",
    "        self.margin_totals[start:stop] += margins\n",
    "\n",
    "        return self\n",
    "    \n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def compute(self, epochs):\n",
    "        \"\"\"\n",
    "        Returns the AUM values.\n",
    "\n",
    "        Args:\n",
    "            epochs (int): The number of training epochs that have occurred.\n",
    "        \"\"\"\n",
    "        return self.margin_totals / epochs\n",
    "    \n",
    "    @torch.inference_mode()\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the state.\n",
    "        \"\"\"\n",
    "        self.margin_totals = torch.zeros((self.num_examples,), device=self.device)\n",
    "\n",
    "\n",
    "aum = AUM(num_examples=len(threshold_dataset), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader, model, loss_fn, optimizer, epoch, writer, loss_metric, accuracy_metric, aum):\n",
    "    model.train()\n",
    "    with tqdm(loader) as progress:\n",
    "        for batch, (x, y) in enumerate(progress):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss_metric.update(loss.detach())\n",
    "            accuracy_metric.update(pred, y)\n",
    "\n",
    "            progress.set_postfix_str(\n",
    "                f\"loss={loss_metric.compute().item():.4f}, accuracy={accuracy_metric.compute().item():.2%}\",\n",
    "                refresh=False\n",
    "            )\n",
    "\n",
    "            aum.update(pred, y, start=loader.batch_size * batch)\n",
    "\n",
    "    writer.add_scalar(\"loss/train\", scalar_value=loss_metric.compute(), global_step=epoch)\n",
    "    loss_metric.reset()\n",
    "    writer.add_scalar(\"accuracy/train\", scalar_value=accuracy_metric.compute(), global_step=epoch)\n",
    "    accuracy_metric.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, model, loss_fn, epoch, writer, loss_metric, accuracy_metric, classes):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            loss_metric.update(loss)\n",
    "            accuracy_metric.update(pred, y)\n",
    "    \n",
    "    print(f\"test_loss={loss_metric.compute().item():.4f}, test_accuracy={accuracy_metric.compute().item():.2%}\")\n",
    "\n",
    "    writer.add_scalar(\"loss/test\", scalar_value=loss_metric.compute(), global_step=epoch)\n",
    "    loss_metric.reset()\n",
    "    writer.add_scalar(\"accuracy/test\", scalar_value=accuracy_metric.compute(), global_step=epoch)\n",
    "    accuracy_metric.reset()\n",
    "\n",
    "    x, y = zip(*random.choices(loader.dataset, k=4))\n",
    "    x = torch.stack(x)\n",
    "    y = torch.tensor(y)\n",
    "    writer.add_figure(\"predictions\", plot_classes_preds(model, x, y, classes), global_step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "epochs = 15\n",
    "for epoch in range(epochs):\n",
    "    print(\"-------------------------------\")\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    train(threshold_loader, model, loss_fn, optimizer, epoch, writer, loss_metric, accuracy_metric, aum)\n",
    "    test(test_loader, model, loss_fn, epoch, writer, loss_metric, accuracy_metric, classes=threshold_loader.dataset.classes)\n",
    "print(\"-------------------------------\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aum_values = aum.compute(epochs).cpu().numpy()\n",
    "\n",
    "print(f\"AUM values: {aum_values.shape}, {aum_values.dtype}\")\n",
    "print(f\"mean: {np.mean(aum_values):.4f}, min: {np.min(aum_values):.4f}, max: {np.max(aum_values):.4f}, std: {np.std(aum_values):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute AUM threshold\n",
    "\n",
    "threshold_sample_aum_values = aum_values[threshold_sample_flags == 1]\n",
    "threshold_sample_aum_percentile = 0.99\n",
    "aum_threshold = np.percentile(threshold_sample_aum_values, threshold_sample_aum_percentile)\n",
    "\n",
    "print(f\"AUM threshold: {aum_threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mislabeled_example_flags = (threshold_sample_flags == 0) & (aum_values <= aum_threshold)\n",
    "mislabeled_example_flags = mislabeled_example_flags.astype(threshold_sample_flags.dtype)\n",
    "print(f\"Mislabeled example flags: {mislabeled_example_flags.shape}, {mislabeled_example_flags.dtype}\")\n",
    "print(f\"Potentially mislabeled examples: {np.sum(mislabeled_example_flags)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mislabeled_examples(model, dataset, mislabeled_example_flags, classes):\n",
    "    (mislabeled_example_indexes,) = np.nonzero(mislabeled_example_flags)\n",
    "    indexes = np.random.choice(mislabeled_example_indexes, 6)\n",
    "    fig, axs = plt.subplots(1, 6, figsize=(15, 3.8))\n",
    "    fig.suptitle(\"Potentially mislabeled examples\")\n",
    "    for i, ax in enumerate(axs):\n",
    "        x, y = dataset[indexes[i]]\n",
    "        with torch.no_grad():\n",
    "            pred = model(x.to(device)[None])[0].argmax(0)\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "        ax.imshow(to_pil_image(x))\n",
    "        ax.set_title(f\"{classes[y]}\\nAUM={aum_values[indexes[i]]:.4f}\\n(predicted: {classes[pred]})\")\n",
    "\n",
    "\n",
    "plot_mislabeled_examples(model, threshold_dataset, mislabeled_example_flags, threshold_dataset.classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
